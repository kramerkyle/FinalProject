{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4048d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb463ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'EPA_Walkability_Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAVANN~1\\AppData\\Local\\Temp/ipykernel_17148/1210668319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load the CSV into a Dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mepa_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mepa_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EPA_Walkability_Data.csv'"
     ]
    }
   ],
   "source": [
    "# Name the file variable\n",
    "file = 'EPA_Walkability_Data.csv'\n",
    "\n",
    "# Load the CSV into a Dataframe\n",
    "epa_df = pd.read_csv(file)\n",
    "epa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f8d9f3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epa_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAVANN~1\\AppData\\Local\\Temp/ipykernel_17148/3847756560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepa_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'epa_df' is not defined"
     ]
    }
   ],
   "source": [
    "list(epa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aac7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b171b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Necessary Columns and Renaming Columns\n",
    "epa_columns_df = epa_df[['GEOID10', 'GEOID20', 'STATEFP', 'COUNTYFP', 'TRACTCE', 'NatWalkInd', 'CountHU', 'TotPop', 'Pct_AO0', 'Pct_AO1', 'Pct_AO2p', 'R_PCTLOWWAGE', 'D1A', 'D1B', 'D1C', 'D3APO', 'D4D']]\n",
    "epa_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_renamed_df = epa_columns_df.rename(\n",
    "    columns={'GEOID10':'2010 Census ID',\n",
    "            'GEOID20': '2018 Census ID',\n",
    "            'STATEFP': 'State FIPS',\n",
    "            'COUNTYFP': 'County FIPS',\n",
    "            'TRACTCE': 'Tract FIPS',\n",
    "            'NatWalkInd': 'Walkability',\n",
    "            'CountHU': 'Number of Households',\n",
    "            'TotPop': 'Total Population',\n",
    "            'Pct_AO0': '% 0 Vehicle HH',\n",
    "            'Pct_AO1': '% 1 Vehicle HH',\n",
    "            'Pct_AO2p': '% 2+ Vehicle HH',\n",
    "            'R_PCTLOWWAGE': '% Low Wage Workers',\n",
    "            'D1A': 'Residential Density',\n",
    "            'D1B': 'Population Density',\n",
    "            'D1C': 'Employment Density',\n",
    "            'D3APO': 'Pedestrian Network Density',\n",
    "            'D4D': 'Transit Frequency'})\n",
    "\n",
    "epa_renamed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "epa_renamed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a588187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will need to find new dataset on housing density so as not to skew results.\n",
    "# Drop two columns with significant null values\n",
    "epa_renamed_df.drop(['Number of Households', 'Residential Density'], axis=1, inplace=True)\n",
    "\n",
    "epa_renamed_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce706f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null rows\n",
    "epa_clean_df = epa_renamed_df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823a4e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that null values are dropped\n",
    "epa_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Census Tract IDs\n",
    "epa_columns_df = epa_clean_df[['2010 Census ID', 'Tract FIPS','State FIPS', 'County FIPS', 'Walkability', 'Total Population', '% 0 Vehicle HH', '% 1 Vehicle HH', '% 2+ Vehicle HH', 'Pedestrian Network Density', 'Transit Frequency']]\n",
    "epa_columns_df.set_index(['State FIPS'], inplace=True)\n",
    "epa_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf502eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_columns_df['2010 Census ID'] = epa_columns_df['2010 Census ID'].div(10000000)\n",
    "epa_columns_df                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edd18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_columns_df['2010 Census ID'] = epa_columns_df['2010 Census ID'].astype(int)\n",
    "epa_columns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the state FIPS code CSV\n",
    "state_code_file = 'StatesFIPSCodes.csv'\n",
    "state_df = pd.read_csv(state_code_file)\n",
    "state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9707d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_columns_df = state_df[['STATE_FIPS', 'STATE_NAME']]\n",
    "state_columns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb761485",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_renamed_df = state_columns_df.rename(\n",
    "    columns={'STATE_FIPS':'State FIPS',\n",
    "            'STATE_NAME': 'State'})\n",
    "state_renamed_df.set_index(['State FIPS'], inplace=True)\n",
    "state_renamed_df.head()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "epa_states = epa_columns_df.merge(state_renamed_df, how='inner', on='State FIPS')\n",
    "epa_states.set_index(['State'], inplace=True)\n",
    "epa_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db333b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_epa_df = epa_states.rename(\n",
    "    columns={'2010 Census ID':'Census Tract Number'})\n",
    "clean_epa_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd864bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Name the file variable\n",
    "food_file = 'food_access_clean.csv'\n",
    "\n",
    "# Load the CSV into a Dataframe\n",
    "food_df = pd.read_csv(food_file, names=['Census Tract Number', 'State', 'County', 'LILA 1 and 10', 'LILA 0.5 and 10', 'LILA 1 and 20', 'LILA Vehicle'])\n",
    "food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b80f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df['Census Tract Number'] = food_df['Census Tract Number'].astype(str)\n",
    "food_df['Census Tract Number'] = food_df['Census Tract Number'].str[5:].astype(int)\n",
    "food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_food_df = food_df.merge(clean_epa_df, how='inner', on='Census Tract Number')\n",
    "walk_food_df.set_index(['Census Tract Number'], inplace=True)\n",
    "walk_food_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65e967",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = walk_food_df.sort_index()\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_location_df = sorted_df[['State', 'County', 'Total Population', 'Walkability', 'Pedestrian Network Density', 'Transit Frequency', '% 0 Vehicle HH', '% 1 Vehicle HH', '% 2+ Vehicle HH', 'LILA 1 and 10', 'LILA 0.5 and 10', 'LILA 1 and 20', 'LILA Vehicle']]\n",
    "cleaned_location_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_location_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a2e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to a CSV\n",
    "cleaned_location_df.to_csv('location_data.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d50822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
